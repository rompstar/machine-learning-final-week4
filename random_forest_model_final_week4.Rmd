---
title: "Final Project - Machine Learning - Week 4"
author: "Raymond Miecznik"
date: "4/29/2018"
output:
  html_document: default
  pdf_document: default
---

```{r background, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Practical Machine Learning

Project Background

Using devices such as Jawbone Up, Nike FuelBand, and Fitbit it is now possible to collect a large amount of data about personal activity relatively inexpensively. These type of devices are part of the quantified self movement - a group of enthusiasts who take measurements about themselves regularly to improve their health, to find patterns in their behavior, or because they are tech geeks. 

One thing that people regularly do is quantify how much of a particular activity they do, but they rarely quantify how well they do it. In this project, your goal will be to use data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants. 

They were asked to perform barbell lifts correctly and incorrectly in 5 different ways. 

More information is available from the website here: 

http://web.archive.org/web/20161224072740/http:/groupware.les.inf.puc-rio.br/har (see the section on the Weight Lifting Exercise Dataset).

Data

The training data for this project are available here:

https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv

The test data are available here:

https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv

## About Random Forrest Model - background basics

For this model we will be using Random forests which is a way of averaging multiple deep decision trees, trained on different parts of the same training set (partitions), with the goal of overcoming over-fitting problems.  Random forests are an ensemble learning method used in classification and regression.


## Dependencies and Grab the Data

```{r setup, cache=TRUE, message=FALSE}

# load up all the libraries that will be used
library(caret)
library(randomForest)
library(RCurl)
library(psych)

# download all the data from these sources keeping them in their original .csv state
download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv",destfile="training.csv",method="libcurl")
download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv",destfile=".csv",method="libcurl")

# also download into an object
training_url <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
testing_url <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
train_url <- getURL(training_url)
test_url <- getURL(testing_url)

train_data <- read.csv(textConnection(train_url), header = TRUE,na.strings = c("NA","NaN","","#DIV/0!"))
test_data <- read.csv(textConnection(test_url), header = TRUE,na.strings = c("NA","NaN","","#DIV/0!"))

# the train set has 19,622 observations with 160 variables

```

## Data preparation and Cleanup

Inspect, clean the dataset, remove any obvious columns not useful to the model from visual inspection, also inspect all the columns for NA values and removed anything greater than 50%.


```{r prepare, cache=TRUE, message=FALSE}

#summary(train_data)
#summary(test_data)

# remove any columns from the dataset where the NA's GREATER THAN (>) .50 (keeping .50 its self) 
# reduced from 160 to 60 columns
train_data_clean <- train_data[, -which(colMeans(is.na(train_data)) > 0.50)]

# removed any columns which appear not needed upon a visual inspection / the first 6 columns in the dataset are not needed
var.out.bool <- !names(train_data_clean) %in% c('X','user_name','raw_timestamp_part_1','raw_timestamp_part_2','cvtd_timestamp','new_window')
train_data_clean2 <- train_data_clean[,var.out.bool]

# as last step, check if there are any duplicate columns left
duplicated(colnames(train_data_clean2))
length(duplicated(train_data_clean2$column_name))

```

## Run the Random Forest model

A Random Forest model will be run with 5-Fold cross validation.  This might take a good 40 minutes+ without utilizing speed-up mechanisms.

Random Forest can be difficult to interpret because of the multiple prediction trees, but it is highly accurate.

The ensemble model will average out all the values.


```{r model, cache=TRUE}

# list the distinct unique Response variable values
unique(train_data_clean2$classe)
# look at them quickly
plot(train_data_clean2$classe)

# run the model
random_forest_model <- train(classe ~. , data = train_data_clean2, method = "rf", trControl=trainControl(method="cv",number=5) )

# save the model for reference
save(random_forest_model,file="rf_10fold_cv_model.Rda")

# look at the model output
print(random_forest_model)

# plot the model
plot(random_forest_model)

# list and plot the top variables with most importance 
varImp(random_forest_model)
plot(varImp(random_forest_model))

random_forest_model$finalModel

# model aapears to have a high accuracy percentage
# intersect the test data over the clean training data, so that we are final testing on the same variables and clean data state
final_test <- test_data[,intersect(names(train_data_clean2),names(test_data))] 

# run the final test on the predictions against the 
  
final_model_predictions <- predict(random_forest_model, final_test)

confusionMatrix(random_forest_model, test_data$classe)

# save the predictions for the 20 Question Final Quiz
for_Quiz_Answers <- as.data.frame(final_model_predictions)


```


## The OOB 'Out-of-Bag' 


The OOB error estimate is at % 0.0011 - which is considered low.

Sufficient accurancy exists at 99.81% to proceed forward in using the model.


